NAME:Oliver Goch
EMAIL:the.oliver.goch@gmail.com
ID:123456789

lab2_add.c: This is the multithreaded add program. It adds 1 then subtracts 1. There are optional command line arguments for the number of threads, the number of iterations, whether to yield, which calls sched_yield(), or synchronization options. The synchronization options are s for spin lock, m for mutex lock, and c for a compare and swap with atomic instructions style lock.

SortedList.h: Contains the functions and descriptions for the SortedList implementation.

SortedList.c: Contains the implementaiton for the SortedList Linked List.

lab2_list.c: This is the multithreaded linked list program. There are optional command line arguments for the number of threads, the number of iterations, whether to yield and where to yield, which calls sched_yield(), or synchronization options. The synchronization options are s for spin lock and m for mutex lock.

Makefile: A Makefile that has options for build that builds both programs, tests that runs over 200 tests and generates CSV files, graphs that generates the necesary graphs, dist that makes the distribution tarball, and clean that removes all generated files.

.png files: Each one has a graph that was generated by the graphs command.

README: The file that has a description of all other files, including this one! Also has answers to all the questions.

QUESTIONS

QUESTION 2.1.1 - causing conflicts:
Why does it take many iterations before errors are seen?
Why does a significantly smaller number of iterations so seldom fail?

ANSWER: It takes many iterations because the race conditions are less likely to result in a miscalculation with less iterations. Becasue each thread has to do less iterations, it is more likely that one thread will finish before another can begin.


QUESTION 2.1.2 - cost of yielding:
Why are the --yield runs so much slower?
Where is the additional time going?
Is it possible to get valid per-operation timings if we are using the --yield option?
If so, explain how. If not, explain why not.

ANSWER: Yield gives up control of the CPU and switches to another thread. This will be done with a context switch. The yield runs slower because of the context switch and this is where the additional time goes. We cannot get accurate timing with the --yiled option because we are counting the overall time, which includes the time of the context switch. To find the per-operation timing without the --yield option we would need to take out the time of the context switch. Without knowing, how long that is, it is impossible to find the per-operation time.

QUESTION 2.1.3 - measurement errors:
Why does the average cost per operation drop with increasing iterations?
If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?

ANSWER: The average cost per operation drops with increasing iterations because there is less overhead. For one operation it is quite expensive to create the thread and run it. When multiple iterations are called, the cost goes down because of the reuse of resources. The functions and threads do not need to recreated for each iteration, so this will save on the cost per operation. The "correct" cost is between 100,000 and 1,000,000 iterations as the cost decreases with the number of iterations but then jumps back up at 1,000,000 with the number of iterations.

QUESTION 2.1.4 - costs of serialization:
Why do all of the options perform similarly for low numbers of threads?
Why do the three protected operations slow down as the number of threads rises?

ANSWER: They perform similarly because there is less contention for the resource and less of a queue. The three protected operations slow down as the number of threads rise because the contention for the resource rises. The more threads competing for the resource, the longer the queue will be and the more time it will take to get through it.

QUESTION 2.2.1 - scalability of Mutex
Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

ANSWER: Both vary somewhat linearly with the number of threads. For add, it is initially very sharp, but it flattens out quite a bit. This probably happens due to the overhead of the mutex lock. The list time per operation reamins fairly linear, most likely due to the constant contention of resource, so the overhead cost will remain the same. 


QUESTION 2.2.2 - scalability of spin locks

Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

ANSWER: Spin lock time increases very sharply for both list and add, as they take a lot of time and can burn CPU if an operation holds the lock for a long time. Mutex time also increases linearly but not quite as steep, due to the more efficient nature of mutex locks. 
